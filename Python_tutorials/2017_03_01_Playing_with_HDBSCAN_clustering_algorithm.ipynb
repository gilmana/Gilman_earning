{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with HDBSCAN \n",
    "\n",
    "### Objective: to understand the basics of how to implement hdbscan clustering on my precomputed distance metric table\n",
    "\n",
    "Following basic usage from the HDBSCAN github repository, in the docs directory:\n",
    "https://github.com/scikit-learn-contrib/hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets.samples_generator import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs, labels = make_blobs(n_samples=4000, n_features=8, centers = 4) #creates numpy ndarrays with 4 blob centers\n",
    "type(blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 8)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "print(blobs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.707333</td>\n",
       "      <td>8.452894</td>\n",
       "      <td>8.363299</td>\n",
       "      <td>-2.899506</td>\n",
       "      <td>7.525401</td>\n",
       "      <td>10.012177</td>\n",
       "      <td>7.124912</td>\n",
       "      <td>-9.517923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.342652</td>\n",
       "      <td>-5.772818</td>\n",
       "      <td>0.407365</td>\n",
       "      <td>2.746340</td>\n",
       "      <td>-8.761033</td>\n",
       "      <td>9.122898</td>\n",
       "      <td>1.710239</td>\n",
       "      <td>10.345968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.244715</td>\n",
       "      <td>-10.292425</td>\n",
       "      <td>4.270402</td>\n",
       "      <td>6.608374</td>\n",
       "      <td>3.692815</td>\n",
       "      <td>4.053554</td>\n",
       "      <td>-4.025397</td>\n",
       "      <td>2.589381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.323498</td>\n",
       "      <td>-0.848869</td>\n",
       "      <td>-4.668813</td>\n",
       "      <td>7.090943</td>\n",
       "      <td>-2.282454</td>\n",
       "      <td>8.873566</td>\n",
       "      <td>4.968602</td>\n",
       "      <td>-1.600008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.306039</td>\n",
       "      <td>-6.393436</td>\n",
       "      <td>0.093635</td>\n",
       "      <td>4.210367</td>\n",
       "      <td>-8.623712</td>\n",
       "      <td>9.071091</td>\n",
       "      <td>1.471359</td>\n",
       "      <td>9.653458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2         3         4          5         6  \\\n",
       "0 -0.707333   8.452894  8.363299 -2.899506  7.525401  10.012177  7.124912   \n",
       "1  8.342652  -5.772818  0.407365  2.746340 -8.761033   9.122898  1.710239   \n",
       "2  6.244715 -10.292425  4.270402  6.608374  3.692815   4.053554 -4.025397   \n",
       "3  0.323498  -0.848869 -4.668813  7.090943 -2.282454   8.873566  4.968602   \n",
       "4  8.306039  -6.393436  0.093635  4.210367 -8.623712   9.071091  1.471359   \n",
       "\n",
       "           7  \n",
       "0  -9.517923  \n",
       "1  10.345968  \n",
       "2   2.589381  \n",
       "3  -1.600008  \n",
       "4   9.653458  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blob = pd.DataFrame(blobs) #just a dataframe of the data\n",
    "df_blob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  2\n",
       "1  1\n",
       "2  0\n",
       "3  3\n",
       "4  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.DataFrame(labels) #dont understand why we need these labels? are these column indeces?\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN() #create cluster object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDBSCAN(algorithm='best', allow_single_cluster=False, alpha=1.0,\n",
       "    approx_min_span_tree=True, core_dist_n_jobs=4, gen_min_span_tree=False,\n",
       "    leaf_size=40, match_reference_implementation=False,\n",
       "    memory=Memory(cachedir=None), metric='euclidean', min_cluster_size=5,\n",
       "    min_samples=None, p=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer.fit(blobs) #fit the data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering is complete! to get the results you need the attribute labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data point get a cluster label, cluser 1, cluster 2, cluster 3... an array of integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer.labels_.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indeed there are 4000 data points in this array of integers - same as n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer.labels_.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a total of 4 clusters with labels 0,1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stealing wise words:\n",
    "\n",
    "Importantly HDBSCAN is noise aware -- it has a notion of data samples that are not assigned to any cluster. This is handled by assigning these samples the label -1. But wait, there's more. The hdbscan library implements soft clustering, where wach data point is assigned a cluster membership score ranging from 0.0 to 1.0. A score of 0.0 represents a sample that is not in the cluster at all (all noise points will get this score) while a score of 1.0 represents a sample that is at the heart of the cluster (note that this is not the spatial centroid notion of core). You can access these scores via the probabilities_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.69206705,  0.75816776,  0.95033556, ...,  0.62846889,\n",
       "        0.69155578,  0.80544359])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer.probabilities_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different metrics are supported by HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stealing more wise words:\n",
    "\n",
    "That is all well and good, but even data that is embedded in a vector space may not want to consider distances between data points to be pure Euclidean distance. What can we do in that case? We are still in good shape, since hdbscan supports a wide variety of metrics, which you can set when creating the clusterer object. For example we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, ..., 0, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = hdbscan.HDBSCAN(metric='manhattan')\n",
    "clusterer.fit(blobs)\n",
    "clusterer.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the list of supported metrics from scikit learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arccos': hdbscan.dist_metrics.ArccosDistance,\n",
       " 'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n",
       " 'canberra': hdbscan.dist_metrics.CanberraDistance,\n",
       " 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n",
       " 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n",
       " 'cosine': hdbscan.dist_metrics.ArccosDistance,\n",
       " 'dice': hdbscan.dist_metrics.DiceDistance,\n",
       " 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n",
       " 'hamming': hdbscan.dist_metrics.HammingDistance,\n",
       " 'haversine': hdbscan.dist_metrics.HaversineDistance,\n",
       " 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n",
       " 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n",
       " 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n",
       " 'l1': hdbscan.dist_metrics.ManhattanDistance,\n",
       " 'l2': hdbscan.dist_metrics.EuclideanDistance,\n",
       " 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n",
       " 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n",
       " 'matching': hdbscan.dist_metrics.MatchingDistance,\n",
       " 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n",
       " 'p': hdbscan.dist_metrics.MinkowskiDistance,\n",
       " 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n",
       " 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n",
       " 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n",
       " 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n",
       " 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n",
       " 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n",
       " 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdbscan.dist_metrics.METRIC_MAPPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precomputed Distance metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If you create the clusterer with the metric set to precomputed then the clusterer will assume that, rather than being handed a vector of points in a vector space, it is recieving an all pairs distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, ..., 0, 3, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix = pairwise_distances(blobs)\n",
    "clusterer = hdbscan.HDBSCAN(metric='precomputed')\n",
    "clusterer.fit(distance_matrix)\n",
    "clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_blobs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
